---
title: 양자 기계 학습 라이브러리
author: alexeib2
ms.author: alexei.bocharov@microsoft.com
ms.date: 11/22/2019
ms.topic: article
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: 9a24d0b4145d0db2fd8c4e16be807165fff5fb32
ms.sourcegitcommit: 6bf99d93590d6aa80490e88f2fd74dbbee8e0371
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/06/2020
ms.locfileid: "87868919"
---
# <a name="introduction-to-quantum-machine-learning"></a>퀀텀 Machine Learning 소개

## <a name="framework-and-goals"></a>프레임 워크 및 목표

퀀텀 인코딩 및 정보 처리는 기존 machine learning 퀀텀 분류자에 대 한 강력한 대안입니다. 특히, 기능 수에 따라 간결한 형식의 퀀텀 레지스터에 데이터를 인코딩하고, 양자를 계산 리소스로 체계적으로 사용 하 고, 클래스 유추를 위한 퀀텀 측정을 적용 하는 것이 좋습니다.
회로 중심 퀀텀 분류자는 데이터 인코딩을 빠르게 entangling/disentangling 퀀텀 회로와 결합 하 여 데이터 예제의 클래스 레이블을 유추 하는 비교적 간단한 퀀텀 솔루션입니다.
목표는 매우 큰 기능 공간에 대해서도 회로 매개 변수의 하이브리드 퀀텀/클래식 교육 뿐만 아니라 주체 회로의 기존 특성 및 저장소를 보장 하는 것입니다.

## <a name="classifier-architecture"></a>분류자 아키텍처

분류는 감독 된 기계 학습 작업으로, \{ \} 특정 데이터 샘플의 클래스 레이블 $ y_1, y_2, \ldots, y_d $를 유추 하는 것입니다. "학습 데이터 집합"은 \{ 미리 할당 된 알려진 레이블이 있는 samples $ \mathcal{D} = (x, y)} $의 컬렉션입니다. $X 여기에서 $는 데이터 샘플 이며 $y $는 알려진 레이블 "학습 레이블"입니다.
기존 메서드와 약간 비슷하며 퀀텀 분류는 다음 세 단계로 구성 됩니다.
- 데이터 인코딩
- 분류자 상태 준비
- 측정 확률 측정의 특성으로 인해 이러한 세 단계를 여러 번 반복 해야 합니다. 측정은 비선형 활성화에 해당 하는 퀀텀으로 볼 수 있습니다.
분류자 상태의 인코딩과 컴퓨팅은 모두 *퀀텀 회로*를 통해 수행 됩니다. 인코딩 회로는 일반적으로 데이터를 기반으로 하 고 매개 변수를 사용 하지 않는 반면 분류자 회로는 충분 한 learnable 매개 변수 집합을 포함 합니다. 

제안 된 솔루션에서 분류자 회로는 단일의 비트 회전 및 2 중 비트 제어 회전으로 구성 됩니다. 여기서 learnable 매개 변수는 회전 각도입니다. 회전 및 제어 된 회전 게이트는 퀀텀 계산에 대해 *universal* 이라고 하며,이는 모든 단일 무게 매트릭스가 이러한 게이트로 구성 된 길고 충분 한 회로로 분해할 수 있음을 의미 합니다.

![다중 계층 퍼셉트론 및 회로 중심의 분류자](~/media/DLvsQCC.png)

기본 구조를 더 잘 이해 하기 위해이 모델을 다중 계층 퍼셉트론과 비교할 수 있습니다. 퍼셉트론에서 예측 $p (y | x, \theta) $는 비 선형 활성화 함수 (neurons)를 연결 하는 선형 함수를 결정 하는 가중치 $ \theta $로 매개 변수가 있는 됩니다. 이러한 매개 변수를 학습 하 여 모델을 만들 수 있습니다. 출력 계층에서 소프트 max와 같은 비선형 활성화 함수를 사용 하 여 클래스에 속한 샘플의 확률을 얻을 수 있습니다. 회로 중심 분류자에서 예측은 모델 회로의 단선 비트 및 2-매개 변수가 있는 비트 제어 회전의 회전 각도에 의해 조정 됩니다. 이와 비슷한 방식으로 이러한 매개 변수는 그라데이션 디센더 알고리즘의 하이브리드 퀀텀/클래식 버전에서 학습 될 수 있습니다. 선형이 아닌 활성화 함수를 사용 하는 대신 출력을 계산 하기 위해 제어 되는 회전 후 특정 비트에 대해 반복 측정을 읽어 클래스의 확률을 가져옵니다. 퀀텀 상태에서 기존 데이터를 인코딩하려면 상태 준비를 위해 제어 가능한 인코딩 회로를 사용 합니다.

아키텍처는 상대적으로 얕은 회로를 탐색 하므로 모든 범위에서 데이터 기능 간의 상관 관계를 모두 캡처하기 위해 신속 하 게 *entangling* 해야 합니다. 가장 유용한 빠른 entangling 회로 구성 요소의 예는 아래 그림에 나와 있습니다. 이 geometry를 사용 하는 회로가 $3 n + 1 $ 게이트로만 구성 된 경우에도 계산 되는 단일 무게 매트릭스가 $2 ^ n $ 기능 간에 상당한 상호 통신할 수 있도록 합니다.

![5 개의 entangling에서 퀀텀 회로를 빠르게 하 고 두 개의 순환 계층을 사용 합니다.](~/media/5-qubit-qccc.png)

위 예제의 회로는 6 개의 단일 수준 게이트 $ (G_1, \ldots, G_5;로 구성 됩니다. G_ {16} ) $ 및 10 2-stbits 게이트 $ (G_6, \ldots, G_ {15} ) $입니다. 각 게이트가 하나의 learnable 매개 변수를 사용 하 여 정의 되는 것으로 가정 하면 learnable 매개 변수는 16 개 있으며, 5-bit 힐베르트 공간의 차원은 32입니다. $2 ^ n $ 차원 기능 공간에 대 한 $3 n + 1 $ 매개 변수를 사용 하 여 회로를 생성 하 $n $가 홀수 인 경우 이러한 회로 기 하 도형은 $n $-ombit 레지스터에 쉽게 일반화 될 수 있습니다.

## <a name="classifier-training-as-a-supervised-learning-task"></a>감독 된 학습 작업으로 서의 분류자 학습

분류자 모델의 교육은 작업 매개 변수의 최적 값을 찾기 때문에 학습 샘플에서 올바른 학습 레이블을 유추 하는 경우의 평균 가능성을 최대화 합니다.
여기서는 두 가지 수준 분류만 사용 합니다. 즉, $d = $2의 경우와 레이블이 $y _1 인 두 개의 클래스 (y_2 $)만 고려 합니다.

> [!NOTE]
> 메서드를 임의 수의 클래스로 일반화 하는 확실 방법은 qudits를 사용 하 여로 대체 하는 것입니다. 예를 들어, $ 상태를 $d 사용 하는 퀀텀 단위와 $d $ 방향 측정이 있는 두 방향 측정이 있습니다.

### <a name="likelihood-as-the-training-goal"></a>학습 목표의 가능성

Learnable 퀀텀 회로 $U (\ 테타) $를 지정 하는 경우 $ \theta $는 매개 변수의 벡터이 고 $M $로 최종 측정을 나타내는 경우 올바른 레이블 유추의 평균 가능성은 $ $ \begin{align} \mathcal{L} (\theta) = \frac {1} {| \mathcal{D} |} \theta (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 |)입니다. U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \theta) \end{align} $ $ $P where (M = y | z) $는 퀀텀 상태에서 $y $를 측정할 확률 $z $입니다.
여기서는 \mathcal{L} (\theta) $가 $ \theta $에서 부드러운 확률 함수 $ (\theta) $이 고 모든 $ \ theta_j $에서 파생 된 것을 기본적으로 확률 함수 자체를 계산 하는 데 사용 되는 것과 동일한 퀀텀 프로토콜을 사용 하 여 계산할 수 있음을 이해 해야 합니다. 이렇게 하면 $ \mathcal{L} (\theta) $를 그라데이션 디센더로 최적화할 수 있습니다.

### <a name="classifier-bias-and-training-score"></a>분류자 편차 및 학습 점수

$ \Theta $에서 매개 변수의 중간 (또는 최종) 값을 지정 하는 경우 유추를 수행 하기 위한 *분류자 바이어스* 로 지정 된 단일 실수 $b 값을 식별 해야 합니다. 레이블 유추 규칙은 다음과 같이 작동 합니다. 
- 샘플 $x $에는 $P (M = y_2 | 인 경우에만 _2 $ if $y 레이블이 할당 됩니다. U (\theta) x) + b > $0.5 (RULE1) (그렇지 않으면 지정 된 레이블 $y _1 $)

명확 하 게 $b $는 간격 $ (-0.5, + 0.5)에 있어야 합니다.

\Mathcal{D} $의 학습 사례 $ (x, y) \는 RULE1에 대 한 $x $에 대해 유추 된 레이블이 실제로는 $y $와 다른 경우에 대 한 잘못 된 $b *분류* 로 간주 됩니다. 전체 오 분류 수는 바이어스 $b $가 지정 된 경우 분류자의 *학습 점수* 입니다. *최적* 분류자 바이어스 $b $는 학습 점수를 최소화 합니다. 사전 계산 확률 예측이 $ \{ P (M = y_2 |로 지정 된 경우이를 쉽게 확인할 수 있습니다. U (\theta) x) | (x, *) \in\mathcal{D} \} $는 최대 $ \ log_2 (| \mathcal{D} |)를 만들어 간격 $ (-0.5, + 0.5)의 이진 검색에서 최적의 분류자 바이어스를 찾을 수 있습니다. $ 단계.

### <a name="reference"></a>참조

이 정보는 코드로의 재생을 시작 하는 데 충분 해야 합니다. 그러나이 모델에 대 한 자세한 내용은 [ *' 회로 중심 퀀텀 분류자 ', 민 Schuld, Alex Bocharov, Krysta sva및 네 번째 wiebe* 의 원래 제안을 읽어 보세요.](https://arxiv.org/abs/1804.00633)
