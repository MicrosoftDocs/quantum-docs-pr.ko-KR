---
title: 양자 기계 학습 라이브러리
description: 퀀텀 시스템에서 기계 학습을 사용 하는 방법 알아보기
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: conceptual
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: e2f4a4a63eef40474856426b3b29652b5d3053b2
ms.sourcegitcommit: 71605ea9cc630e84e7ef29027e1f0ea06299747e
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/26/2021
ms.locfileid: "98854027"
---
# <a name="introduction-to-quantum-machine-learning"></a>퀀텀 Machine Learning 소개

## <a name="framework-and-goals"></a>프레임 워크 및 목표

퀀텀 인코딩 및 정보 처리는 기존 machine learning 퀀텀 분류자에 대 한 강력한 대안입니다. 특히,이 기능을 사용 하면 퀀텀 되거나 얽 히를 계산 리소스로 사용 하 고 클래스 유추를 위한 퀀텀 측정을 채택 하는 기능 수에 따라 간결한 데이터를 퀀텀 레지스터에서 인코딩할 수 있습니다.
회로 중심 퀀텀 분류자는 데이터 인코딩을 빠르게 entangling/disentangling 퀀텀 회로와 결합 하 여 데이터 예제의 클래스 레이블을 유추 하는 비교적 간단한 퀀텀 솔루션입니다.
목표는 매우 큰 기능 공간에 대해서도 회로 매개 변수의 하이브리드 퀀텀/클래식 교육 뿐만 아니라 주체 회로의 기존 특성 및 저장소를 보장 하는 것입니다.

## <a name="classifier-architecture"></a>분류자 아키텍처

분류는 감독 된 기계 학습 작업으로, \{ \} 특정 데이터 샘플의 클래스 레이블 $ y_1, y_2, \ldots, y_d $를 유추 하는 것입니다. "학습 데이터 집합"은 \{ 미리 할당 된 알려진 레이블이 있는 samples $ \mathcal{D} = (x, y)} $의 컬렉션입니다. $X 여기에서 $는 데이터 샘플 이며 $y $는 알려진 레이블 "학습 레이블"입니다.
기존 메서드와 약간 비슷하며 퀀텀 분류는 다음 세 단계로 구성 됩니다.
- 데이터 인코딩
- 분류자 상태 준비
- 측정 확률 측정의 특성으로 인해 이러한 세 단계를 여러 번 반복 해야 합니다. 분류자 상태의 인코딩과 컴퓨팅은 모두 *퀀텀 회로* 를 통해 수행 됩니다. 인코딩 회로는 일반적으로 데이터를 기반으로 하 고 매개 변수를 사용 하지 않는 반면 분류자 회로는 충분 한 learnable 매개 변수 집합을 포함 합니다. 

제안 된 솔루션에서 분류자 회로는 단일의 비트 회전 및 2 중 비트 제어 회전으로 구성 됩니다. 여기서 learnable 매개 변수는 회전 각도입니다. 회전 및 제어 된 회전 게이트는 퀀텀 계산에 대해 *universal* 이라고 하며,이는 모든 단일 무게 매트릭스가 이러한 게이트로 구성 된 길고 충분 한 회로로 분해할 수 있음을 의미 합니다.

제안 된 버전에서는 단일 주파수 예측이 이어지는 회로 한 개만 지원 됩니다.
따라서이 솔루션은 낮은 수준의 다항식 커널을 사용 하는 지원 벡터 컴퓨터에서 아날로그 인 퀀텀입니다.

![다중 계층 퍼셉트론 및 회로 중심의 분류자](~/media/DLvsQCC.png)

간단한 퀀텀 분류자 디자인은 기존 SVM (support vector machine) 솔루션과 비교할 수 있습니다. SVM의 경우 데이터 샘플 $x $에 대 한 유추는 최적의 커널 형식 $ \sum \ alpha_j k (x_j, x) $를 사용 하 여 수행 됩니다. 여기서 $k $는 특정 커널 함수입니다.

이와 대조적으로 퀀텀 분류자는 $p 예측을 사용 하는 것과 유사 하지만 기술적으로는 다른 │ (〈 U) x | M | U (\theta) x 〉 $를 사용 합니다. 따라서 간단한 진폭 인코딩을 사용 하는 경우 $p (y │ x, U (\theta)) $는 $x $의 amplitudes에서 정방형 형태 이지만이 폼의 계수는 더 이상 독립적으로 학습 되지 않습니다. 이는 회로 $U (\theta) $의 matrix 요소에서 집계 되며, 일반적으로 벡터 $x $의 차원 보다 learnable 매개 변수 $ \theta $가 훨씬 적습니다. 원본 기능의 $p (y │ x, U (\theta)) $는 $l $ $x $ 복사본에서 퀀텀 제품 인코딩을 사용 하 여 $2 ^ l $로 늘릴 수 있습니다.

아키텍처는 상대적으로 얕은 회로를 탐색 하므로 모든 범위에서 데이터 기능 간의 상관 관계를 모두 캡처하기 위해 신속 하 게 *entangling* 해야 합니다. 가장 유용한 빠른 entangling 회로 구성 요소의 예는 아래 그림에 나와 있습니다. 이 geometry를 사용 하는 회로가 $3 n + 1 $ 게이트로만 구성 된 경우에도 계산 되는 단일 무게 매트릭스가 $2 ^ n $ 기능 간에 상당한 상호 통신할 수 있도록 합니다.

![5 개의 entangling에서 퀀텀 회로를 빠르게 하 고 두 개의 순환 계층을 사용 합니다.](~/media/5-qubit-qccc.png)

위 예제의 회로는 6 개의 단일 수준 게이트 $ (G_1, \ldots, G_5;로 구성 됩니다. G_ {16} ) $ 및 10 2-stbits 게이트 $ (G_6, \ldots, G_ {15} ) $입니다. 각 게이트가 하나의 learnable 매개 변수를 사용 하 여 정의 되는 것으로 가정 하면 learnable 매개 변수는 16 개 있으며, 5-bit 힐베르트 공간의 차원은 32입니다. $2 ^ n $ 차원 기능 공간에 대 한 $3 n + 1 $ 매개 변수를 사용 하 여 회로를 생성 하 $n $가 홀수 인 경우 이러한 회로 기 하 도형은 $n $-ombit 레지스터에 쉽게 일반화 될 수 있습니다.

## <a name="classifier-training-as-a-supervised-learning-task"></a>감독 된 학습 작업으로 서의 분류자 학습

분류자 모델의 교육은 작업 매개 변수의 최적 값을 찾기 때문에 학습 샘플에서 올바른 학습 레이블을 유추 하는 경우의 평균 가능성을 최대화 합니다.
여기서는 두 가지 수준 분류만 사용 합니다. 즉, $d = $2의 경우와 레이블이 $y _1 인 두 개의 클래스 (y_2 $)만 고려 합니다.

> [!NOTE]
> 메서드를 임의 수의 클래스로 일반화 하는 확실 방법은 qudits를 사용 하 여로 대체 하는 것입니다. 예를 들어, $ 상태를 $d 사용 하는 퀀텀 단위와 $d $ 방향 측정이 있는 두 방향 측정이 있습니다.

### <a name="likelihood-as-the-training-goal"></a>학습 목표의 가능성

Learnable 퀀텀 회로 $U (\ 테타) $를 지정 하는 경우 $ \theta $는 매개 변수의 벡터이 고 $M $로 최종 측정을 나타내는 경우 올바른 레이블 유추의 평균 가능성은 $ $ \begin{align} \mathcal{L} (\theta) = \frac {1} {| \mathcal{D} |} \theta (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 |)입니다. U (\theta) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 | U (\theta) x) \theta) \end{align} $ $ $P where (M = y | z) $는 퀀텀 상태에서 $y $를 측정할 확률 $z $입니다.
여기서는 \mathcal{L} (\theta) $가 $ \theta $에서 부드러운 확률 함수 $ (\theta) $이 고 모든 $ \ theta_j $에서 파생 된 것을 기본적으로 확률 함수 자체를 계산 하는 데 사용 되는 것과 동일한 퀀텀 프로토콜을 사용 하 여 계산할 수 있음을 이해 해야 합니다. 이렇게 하면 $ \mathcal{L} (\theta) $를 그라데이션 디센더로 최적화할 수 있습니다.

### <a name="classifier-bias-and-training-score"></a>분류자 편차 및 학습 점수

$ \Theta $에서 매개 변수의 중간 (또는 최종) 값을 지정 하는 경우 유추를 수행 하기 위한 *분류자 바이어스* 로 지정 된 단일 실수 $b 값을 식별 해야 합니다. 레이블 유추 규칙은 다음과 같이 작동 합니다. 
- 샘플 $x $에는 $P (M = y_2 | 인 경우에만 _2 $ if $y 레이블이 할당 됩니다. U (\theta) x) + b > $0.5 (RULE1) (그렇지 않으면 지정 된 레이블 $y _1 $)

명확 하 게 $b $는 간격 $ (-0.5, + 0.5)에 있어야 합니다.

\Mathcal{D} $의 학습 사례 $ (x, y) \는 RULE1에 대 한 $x $에 대해 유추 된 레이블이 실제로는 $y $와 다른 경우에 대 한 잘못 된 $b *분류* 로 간주 됩니다. 전체 오 분류 수는 바이어스 $b $가 지정 된 경우 분류자의 *학습 점수* 입니다. *최적* 분류자 바이어스 $b $는 학습 점수를 최소화 합니다. 사전 계산 확률 예측이 $ \{ P (M = y_2 |로 지정 된 경우이를 쉽게 확인할 수 있습니다. U (\theta) x) | (x, *) \in\mathcal{D} \} $는 최대 $ \ log_2 (| \mathcal{D} |)를 만들어 간격 $ (-0.5, + 0.5)의 이진 검색에서 최적의 분류자 바이어스를 찾을 수 있습니다. $ 단계.

### <a name="reference"></a>참조

이 정보는 코드로의 재생을 시작 하는 데 충분 해야 합니다. 그러나이 모델에 대 한 자세한 내용은 [ *' 회로 중심 퀀텀 분류자 ', 민 Schuld, Alex Bocharov, Krysta sva및 네 번째 wiebe* 의 원래 제안을 읽어 보세요.](https://arxiv.org/abs/1804.00633)

다음 단계에서 볼 수 있는 코드 샘플 외에 [이 자습서](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification) 에서 퀀텀 분류 탐색을 시작할 수도 있습니다. 
